{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "UPPfSPRxrrCb"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def statistics(pred_labels, true_labels):\n",
        "    # Create a confusion matrix\n",
        "    num_classes = 3\n",
        "    confusion_matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
        "\n",
        "    # Populate the confusion matrix\n",
        "    for true, pred in zip(true_labels, pred_labels):\n",
        "        confusion_matrix[true, pred] += 1\n",
        "\n",
        "    # Initialize metrics\n",
        "    precision = np.zeros(num_classes)\n",
        "    recall = np.zeros(num_classes)\n",
        "    f1_score = np.zeros(num_classes)\n",
        "    support = np.zeros(num_classes)\n",
        "\n",
        "    # Calculate metrics for each class\n",
        "    for i in range(num_classes):\n",
        "        TP = confusion_matrix[i, i]\n",
        "        FP = np.sum(confusion_matrix[:, i]) - TP\n",
        "        FN = np.sum(confusion_matrix[i, :]) - TP\n",
        "        TN = np.sum(confusion_matrix) - (TP + FP + FN)\n",
        "\n",
        "        # Precision, Recall, F1 Score\n",
        "        precision[i] = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "        recall[i] = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "        f1_score[i] = 2 * (precision[i] * recall[i]) / (precision[i] + recall[i]) if (precision[i] + recall[i]) > 0 else 0\n",
        "\n",
        "        # Support (number of true instances for each class)\n",
        "        support[i] = TP + FN\n",
        "\n",
        "    # Calculate weighted averages\n",
        "    weighted_precision = np.sum(precision * support) / np.sum(support) if np.sum(support) > 0 else 0\n",
        "    weighted_recall = np.sum(recall * support) / np.sum(support) if np.sum(support) > 0 else 0\n",
        "    weighted_f1 = np.sum(f1_score * support) / np.sum(support) if np.sum(support) > 0 else 0\n",
        "\n",
        "    return {\n",
        "        'confusion_matrix': confusion_matrix,\n",
        "        'weighted_precision': weighted_precision,\n",
        "        'weighted_recall': weighted_recall,\n",
        "        'weighted_f1': weighted_f1\n",
        "    }"
      ],
      "metadata": {
        "id": "0J6yeKpFycJI"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "pred_labels = [0, 1, 2, 0, 1, 2, 1, 0, 2, 1]  # Predicted labels\n",
        "true_labels = [0, 1, 1, 0, 0, 2, 1, 1, 2, 2]  # True labels\n",
        "\n",
        "#pred_labels = np.random.randint(0, 16, size=100)  # Random predictions\n",
        "#true_labels = np.random.randint(0, 16, size=100)  # Random true labels\n",
        "\n",
        "results = statistics(pred_labels, true_labels)\n",
        "print(\"Confusion Matrix:\\n\", results['confusion_matrix'])\n",
        "print(\"Weighted Precision:\", results['weighted_precision'])\n",
        "print(\"Weighted Recall:\", results['weighted_recall'])\n",
        "print(\"Weighted F1 Score:\", results['weighted_f1'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqmTXLTwzFbe",
        "outputId": "31b12fcf-51eb-4d39-98c0-8c3fdd12bc93"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[2 1 0]\n",
            " [1 2 1]\n",
            " [0 1 2]]\n",
            "Weighted Precision: 0.6\n",
            "Weighted Recall: 0.6\n",
            "Weighted F1 Score: 0.6\n"
          ]
        }
      ]
    }
  ]
}